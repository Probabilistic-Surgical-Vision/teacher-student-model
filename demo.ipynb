{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Randomly Connected Neural Networks for Self-Supervised Monocular Depth Estimation_ Demo Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import yaml\n",
    "\n",
    "from loaders import CityScapesDataset\n",
    "\n",
    "from model import RandomlyConnectedModel\n",
    "\n",
    "import train\n",
    "from train.loss import MonodepthLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") \\\n",
    "    if torch.cuda.is_available() \\\n",
    "        else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yml\") as f:\n",
    "    model_config = yaml.load(f, Loader=yaml.Loader)\n",
    "\n",
    "encoder_config = model_config[\"encoder\"]\n",
    "decoder_config = model_config[\"decoder\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset parameters\n",
    "batch_size = 8\n",
    "validation_samples = 1000\n",
    "numberof_workers = 0\n",
    "\n",
    "# Training parameters\n",
    "numberof_epochs = 1\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    train.transforms.ResizeImage((256, 512)),\n",
    "    train.transforms.RandomFlip(0.5),\n",
    "    train.transforms.ToTensor(),\n",
    "    train.transforms.RandomAugment(0.5, gamma=(0.8, 1.2),\n",
    "                                   brightness=(0.5, 2.0),\n",
    "                                   colour=(0.8, 1.2))\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    train.transforms.ResizeImage((256, 512)),\n",
    "    train.transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CityScapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CityScapesDataset(\"../datasets/cityscapes/\", \"train\",\n",
    "                                  train_transform, limit=200)\n",
    "                                  \n",
    "val_dataset = CityScapesDataset(\"../datasets/cityscapes/\", \"val\",\n",
    "                                val_transform, validation_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                          shuffle=True, num_workers=numberof_workers)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=numberof_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary solution until config code is set up\n",
    "#model = RandomlyConnectedModel(nodes=5, seed=42).to(device)\n",
    "model = RandomlyConnectedModel(load_graph=\"graphs/nodes_5_seed_42\").to(device)\n",
    "#model = RandomlyConnectedModel(encoder_config, decoder_config).to(device)\n",
    "\n",
    "numberof_parameters = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model has {numberof_parameters:,} learnable parameters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.train_model(model, train_loader, numberof_epochs, learning_rate,\n",
    "                  val_loader=val_loader, evaluate_every=1e4, \n",
    "                  save_path=\"trained/\", device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "loss_function = MonodepthLoss()\n",
    "\n",
    "train.evaluate_model(model, val_loader, loss_function,\n",
    "                     save_comparison_to=\"results/\",\n",
    "                     device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"results/comparison.png\")\n",
    "plt.imshow(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e5eae797c35e8ee25ce1c48e15ac48b7aaeab3cd9ec380ff38293f6508486476"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
