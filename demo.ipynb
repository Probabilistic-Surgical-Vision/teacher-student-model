{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Randomly Connected Neural Networks for Self-Supervised Monocular Depth Estimation_ Demo Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% pip install numpy torch torchvision tqdm networkx pyyaml glob pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from model.model import RandomlyConnectedModel\n",
    "from model.train import train_model\n",
    "from model.evaluate import evaluate_model\n",
    "from model.loss import MonodepthLoss\n",
    "\n",
    "from model.transforms import ResizeImage, \\\n",
    "    RandomFlip, ToTensor, RandomAugment\n",
    "    \n",
    "from loaders.cityscapes import CityScapesDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") \\\n",
    "    if torch.cuda.is_available() \\\n",
    "        else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yml\") as f:\n",
    "    model_config = yaml.safe_load(f)\n",
    "\n",
    "encoder_config = model_config[\"encoder\"]\n",
    "decoder_config = model_config[\"decoder\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset parameters\n",
    "batch_size = 8\n",
    "validation_samples = 1000\n",
    "numberof_workers = 8\n",
    "\n",
    "# Training parameters\n",
    "numberof_epochs = 210\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    ResizeImage((256, 512)),\n",
    "    RandomFlip(0.5),\n",
    "    ToTensor(),\n",
    "    RandomAugment((0.8, 1.2), (0.5, 2.0), (0.8, 1.2))\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    ResizeImage((256, 512)),\n",
    "    ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CityScapesDataset(\"datasets/cityscapes/\", \"train\",\n",
    "                                  train_transform)\n",
    "                                  \n",
    "val_dataset = CityScapesDataset(\"datasets/cityscapes/\", \"val\",\n",
    "                                val_transform, validation_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                          shuffle=True, num_workers=numberof_workers)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=numberof_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomlyConnectedModel(encoder_config, decoder_config).to(device)\n",
    "\n",
    "train_model(model, train_loader, numberof_epochs, learning_rate,\n",
    "            val_loader=val_loader, evaluate_every=1e4, \n",
    "            save_path=\"trained/\", device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = MonodepthLoss()\n",
    "\n",
    "evaluate_model(model, val_loader, loss_function,\n",
    "               save_comparison_to=\"results/\",\n",
    "               device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show comparison results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"results/comparison.png\")\n",
    "plt.imshow(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('3.8.12')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "70ac0554d1fc8138b49fb10ebdd30b195d37745d25bc3607903881c8af422237"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
